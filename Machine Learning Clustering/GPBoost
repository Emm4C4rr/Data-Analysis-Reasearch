import pandas as pd
import gpboost as gpb
import numpy as np
from sklearn.model_selection import KFold, train_test_split, ParameterGrid
from sklearn.metrics import r2_score
import shap
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv(
    'C:/Users/emmam/PycharmProjects/pythonProject2/Summer project/data wrangling samples/Sexuality_Crime_2022.csv')

df2 = df.drop(columns=['Unnamed: 0', 'Mn_RT_all_3467', 'PCT_error_3467', 'Stimuli'])

X = df2.drop(['att_7', 'State'], axis=1)
y = df2['att_7']
groups = df2['State']

# Train/test split
X_train, X_test, y_train, y_test, groups_train, groups_test = train_test_split(
    X, y, groups, test_size=0.3, random_state=42
)

# Define parameter grid for grid search
param_grid = {
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 4, 5],
    'min_data_in_leaf': [5, 10, 20],
    'num_boost_round': [50, 100, 150]
}

# KFold cross-validation setup
cv = KFold(n_splits=5, shuffle=True, random_state=42)


# Custom cross-validation function
def custom_cv_gpb(X, y, groups, param_grid, cv):
    best_params = None
    best_score = float('-inf')
    results = []

    # Loop through each combination of parameters
    for params in ParameterGrid(param_grid):
        fold_scores = []

        # Perform K-Fold cross-validation
        for train_index, val_index in cv.split(X):
            X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]
            y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]
            groups_train_fold, groups_val_fold = groups.iloc[train_index], groups.iloc[val_index]

            # Define and train GPModel
            gp_model = gpb.GPModel(group_data=groups_train_fold)
            data_train_fold = gpb.Dataset(X_train_fold, y_train_fold)

            bst = gpb.train(params=params, train_set=data_train_fold, gp_model=gp_model,
                            num_boost_round=params['num_boost_round'])

            # Make predictions
            pred = bst.predict(data=X_val_fold, group_data_pred=groups_val_fold)
            y_pred = pred['response_mean']

            # Compute R-squared for this fold
            r2 = r2_score(y_val_fold, y_pred)
            fold_scores.append(r2)

        # Average score across all folds
        avg_score = np.mean(fold_scores)
        results.append((params, avg_score))

        # Update best score and parameters if current is better
        if avg_score > best_score:
            best_score = avg_score
            best_params = params

    return best_params, best_score, results


# Run custom cross-validation with grid search
best_params, best_score, cv_results = custom_cv_gpb(X_train, y_train, groups_train, param_grid, cv)

print("Best parameters found: ", best_params)
print("Best R-squared score: ", best_score)

# Train final model on the entire training set with the best parameters
gp_model = gpb.GPModel(group_data=groups_train)
data_train = gpb.Dataset(X_train, y_train)

bst = gpb.train(params=best_params, train_set=data_train, gp_model=gp_model,
                num_boost_round=best_params['num_boost_round'])

# Make predictions on the test set
pred = bst.predict(data=X_test, group_data_pred=groups_test)
y_pred = pred['response_mean']

r2_test = r2_score(y_test, y_pred)
print(f"R-squared on test data: {r2_test}")

# Visualisations
# 1. Shap plot
explainer = shap.Explainer(bst)
shap_values = explainer(X_test)

shap.summary_plot(shap_values, X_test, feature_names=X.columns)

# 2. Random Effects Plot
# Extract random effects contributions
pred_latent = bst.predict(data=X_test, group_data_pred=groups_test, pred_latent=True)
random_effects = pred_latent['random_effect_mean']

# Create a DataFrame for random effects
random_effects_df = pd.DataFrame({
    'State': groups_test,
    'Random Effect Contribution': random_effects
})

random_effects_mean = random_effects_df.groupby('State').mean().reset_index()

plt.figure(figsize=(10, 6))
sns.barplot(x='Random Effect Contribution', y='State', data=random_effects_mean.sort_values('Random Effect Contribution'))
plt.title('Random Effects Contributions by State')
plt.xlabel('Mean Random Effect Contribution')
plt.ylabel('State')
plt.show()
