import pandas as pd
from statsmodels.regression.mixed_linear_model import MixedLM
from sklearn.model_selection import train_test_split, KFold, GridSearchCV
import xgboost as xgb
import shap
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('C:/Users/emmam/PycharmProjects/pythonProject2/Summer project/data wrangling samples/Sexuality_Crime_2022.csv')
df2 = df.drop(columns=['Unnamed: 0', 'Mn_RT_all_3467', 'PCT_error_3467', 'Stimuli'])

X = df2.drop(['att_7', 'State'], axis=1)
y = df2['att_7']
Z = pd.DataFrame({'intercept': 1}, index=df2.index)
clusters = df2['State']

# Split data
X_train, X_test, y_train, y_test, clusters_train, clusters_test = train_test_split(
    X, y, clusters, test_size=0.3, random_state=42)

# Fit the Mixed Effects Model
model = MixedLM(y_train, X_train, groups=clusters_train)
result = model.fit()

print(result.summary())
y_pred = result.predict(X_test)

# Calculate R-squared
from sklearn.metrics import r2_score
test_r2 = r2_score(y_test, y_pred)
print("Test R-squared: ", test_r2)

# Feature importance using XGBoost
xgboost_model = xgb.XGBRegressor()
xgboost_model.fit(X_train, y_train)

# Grid Search for hyperparameters
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 4, 5],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.7, 0.8, 0.9],
    'colsample_bytree': [0.7, 0.8, 0.9]
}

cv = KFold(n_splits=5, shuffle=True, random_state=42)
grid_search = GridSearchCV(estimator=xgboost_model, param_grid=param_grid,
                           scoring='r2', cv=cv, verbose=1, n_jobs=-1)
grid_search.fit(X_train, y_train)

best_model = grid_search.best_estimator_
print("Best parameters found: ", grid_search.best_params_)
print("Best R^2 score: ", grid_search.best_score_)

# Test R-squared for the best model
test_r2_best_model = best_model.score(X_test, y_test)
print("Test R-squared for best XGBoost model: ", test_r2_best_model)

# Visulasations
# 1. SHAP plot
explainer = shap.Explainer(best_model)
shap_values = explainer(X_test)

shap.summary_plot(shap_values, X_test, feature_names=['age', 'birthSex', 'sexuality_5', 'race', 'D_score',
                                                      'Overallgayexposure', 'Same_sexRights', 'Tgaymen',
                                                      'Tgayleswomen', 'Tstraightmen', 'Tstraightwomen',
                                                      'religionid', 'education', 'politicalid_7',
                                                      'Assault_Offenses', 'Sex_Offenses', 'Drug_Offenses',
                                                      'Pornographic_Offenses', 'Prostitution_Offenses',
                                                      'Total_SCrimes', 'Total_Crime_rates'])

# 2. Plot Random Effects Contribution
random_effects = result.random_effects
random_effects_df = pd.DataFrame(list(random_effects.items()), columns=['State', 'Random Effect'])
random_effects_df['Random Effect'] = random_effects_df['Random Effect'].apply(lambda x: x[0])  # Extract value from tuple
random_effects_mean = random_effects_df.groupby('State').mean().reset_index()

plt.figure(figsize=(10, 6))
sns.barplot(x='Random Effect', y='State', data=random_effects_mean.sort_values('Random Effect'))
plt.title('Random Effects Contributions by State')
plt.xlabel('Mean Random Effect Contribution')
plt.ylabel('State')
plt.show()
